<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้ | Nick Untitled</title><!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้" />
<meta name="author" content="Kittisak Chotikkakamthorn" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="None" />
<meta property="og:description" content="None" />
<link rel="canonical" href="https://nickuntitled.com/2021/06/26/head-pose-estimation-in-my-thesis-now/" />
<meta property="og:url" content="https://nickuntitled.com/2021/06/26/head-pose-estimation-in-my-thesis-now/" />
<meta property="og:site_name" content="Nick Untitled" />
<meta property="og:image" content="https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/06/Head-Pose-in-Thesis-1200x675.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-26T17:21:34+07:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/06/Head-Pose-in-Thesis-1200x675.jpg" />
<meta property="twitter:title" content="พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Kittisak Chotikkakamthorn"},"dateModified":"2024-03-16T09:46:27+07:00","datePublished":"2021-06-26T17:21:34+07:00","description":"None","headline":"พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้","image":"https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/06/Head-Pose-in-Thesis-1200x675.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://nickuntitled.com/2021/06/26/head-pose-estimation-in-my-thesis-now/"},"url":"https://nickuntitled.com/2021/06/26/head-pose-estimation-in-my-thesis-now/"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://nickuntitled.com/feed.xml" title="Nick Untitled" /><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
  <link rel="stylesheet" href="/assets/css/reset.css" />
  <link rel="stylesheet" href="/assets/css/normalize.css" />
  <link rel="stylesheet" href="/assets/css/main.css" />
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.css" integrity="sha384-OH8qNTHoMMVNVcKdKewlipV4SErXqccxxlg6HC9Cwjr5oZu2AdBej1TndeCirael" crossorigin="anonymous">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Thai:wght@700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Chakra+Petch:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
</head>
<body a="auto">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <p class = 'back-meta'>
    <a href="/">&lt; Nick Untitled</a>
</p><article>
  <h1 class = 'post-title'>พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้</h1>

  <p class="post-meta">
    <time datetime="2021-06-26 17:21:34 +0700">2021-06-26</time>
  </p>

  
  <figure class = 'featured-image'>
      <img src = 'https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/06/Head-Pose-in-Thesis-1200x675.jpg' />
  </figure>
  

  <p><strong>Head Pose Estimation</strong> คือเทคนิคการจับภาพการเคลื่อนไหวของศีรษะเมื่อเทียบกับมุมกล้องที่ถ่ายอยู่ในขณะที่จับภาพ โดยนำภาพใบหน้าของบุคคลที่จับภาพได้จากเทคนิคการจับภาพใบหน้าที่ได้กล่าวถึงในบทความก่อนหน้านี้มาประมวลผลผ่านเทคนิคหนึ่งแล้วระบุเป็นองศาการเคลื่อนไหวของศีรษะใน 3 ทิศทางได้แก่ หันศีรษะซ้าย-ขวา (Yaw), ก้ม-เงยศีรษะ (Pitch) และเอนศีรษะซ้าย-ขวา (Roll)</p>
<p><!--more--></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/06/head-pose-survey.png?w=580&#038;ssl=1" class="kg-image" alt="" loading="lazy" /><figcaption>ทิคทางการหันศีรษะ Yaw, Pitch และ Roll จากเอกสาร Head Pose Estimation in Computer Vision : A Survey</figcaption></figure>
<p>ซึ่งในอดีตจนมาถึงปัจจุบันมีการพัฒนาเทคนิคมาเรื่อย ๆ จนกระทั่งมาถึงปัจจุบันที่นำเทคนิคการเรียนรู้เชิงลึก (Deep Learning) มาใช้งานร่วมด้วย หลังจากการพัฒนาเทคนิค <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" rel="noreferrer noopener">AlexNet ที่ได้ความแม่นยำจากการทดสอบกับฐานข้อมูล ImageNet</a> เนื่องมาจากได้ความแม่นยำ (Accuracy) ที่มากกว่าเทคนิคอื่น กับสามารถจับลักษณะภาพได้โดยอัตโนมัติ (Automatic Feature Extraction) โดยในงานวิจัยที่ทำอยู่นำเทคนิคเหล่านี้มาใช้งาน</p>
<p>เทคนิคหนึ่งที่เรานำมาใช้คือ Hopenet</p>
<h2 id="hopenet">Hopenet</h2>
<figure class="kg-card kg-image-card kg-card-hascaption"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/06/hopenet-architecture.png?w=580&#038;ssl=1" class="kg-image" alt="" loading="lazy" /><figcaption>เทคนิค Hopenet จากเอกสาร Fine-Grained Head Pose Estimation Without Keypoints</figcaption></figure>
<p>เทคนิค Hopenet (เผยแพร่ในเอกสารงานวิจัยที่มีหัวข้อว่า <a href="https://arxiv.org/abs/1710.00925" rel="noreferrer noopener">Fine-Grained Head Pose Estimation Without Keypoints</a>) นี้ที่นำภาพใบหน้าผ่านกระบวนการการเรียนรู้เชิงลึก (Deep Learning) ที่ใช้โครงการเครือข่ายประสาท (Neural Network Architecture) แบบ <a href="https://arxiv.org/abs/1512.03385" rel="noreferrer noopener">ResNet-50</a> แล้วให้ประเมินออกมาเป็นการเคลื่อนไหวของศีรษะและลำคอ 3 ทิศทาง</p>
<p>เราเลยนำเทคนิคนี้จากเว็บ <a href="https://github.com/natanielruiz/deep-head-pose" rel="noreferrer noopener">Github</a> มาทดสอบในเบื้องต้น (Preliminary Study) แล้วได้ความแม่นยำจากการทดสอบฐานข้อมูลสาธารณะอย่าง <a href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm" rel="noreferrer noopener">AFLW2000</a> และ <a href="https://www.kaggle.com/kmader/biwi-kinect-head-pose-database" rel="noreferrer noopener">BIWI</a> มากกว่าเทคนิคอื่นในขณะนั้น</p>
<p>อย่างไรก็ดีงานวิจัยที่ทำอยู่นี้เราต้องจับภาพบริเวณริมฝีปากร่วมด้วย ดังนั้นแล้วเทคนิคนี้เลยไม่ได้ใช้ แล้วจะต้องทำอย่างไรดีล่ะ? เรามาพูดถึงหัวข้อถัดไปดีกว่า ที่เรียกว่า Facial Landmark Detection</p>
<h2 id="facial-landmark-detection">Facial Landmark Detection</h2>
<figure class="kg-card kg-image-card kg-card-hascaption"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/06/landmark-result.jpg?w=580&#038;ssl=1" class="kg-image" alt="" loading="lazy" /><figcaption>Facial Landmark Detection</figcaption></figure>
<p><strong>Facial Landmark Detection</strong> คือกระบวนการจับจุดแลนมาร์คตำแหน่งอวัยวะบนใบหน้าซึ่งเป็นกระบวนการที่สำคัญต่อการนำไปใช้ประมวลผลต่อในงานด้าน Computer Vision งานอื่นต่อไป ได้แก่ กระบวนการการจับภาพการเคลื่อนไหวศีรษะ (Head Pose Estimation) กับกระบวนการจับภาพอารมณ์บนใบหน้า (Facial Emotion Recognition) เป็นต้น</p>
<p>เทคนิคนี้ได้รับการพัฒนามานานเกิน 20 ปีได้แล้ว โดยเทคนิคช่วงแรก ๆ จะเป็นการจับภาพทั้งภาพใบหน้า แล้วแกะลักษณะภาพบนใบหน้า (Feature) เพื่อนำไปประมวลผลผ่านเทคนิคการเรียนรู้ (Machine Learning) ได้แก่</p>
<ul>
<li>Active Shape Model, Active Appearance Model ที่แปลงภาพผ่าน PCA (Principal Component Analysis)</li>
<li>Constrained Local Model ที่ใช้ Point Distribution Model ร่วมกันกับใช้ตำแหน่งภาพตามอวัยวะต่าง ๆ เพื่อปรับจุดบนใบหน้าให้แม่นยำขึ้น</li>
<li>เป็นต้น</li>
</ul>
<p>จนกระทั่ง AlexNet ได้รับการพัฒนาขึ้น มีเทคนิคที่พัฒนาขึ้นจากการเรียนรู้เชิงลึก (Deep Learning) แล้วได้ความแม่นยำมากกว่าเทคนิคอื่น นอกเหนือจากนี้มีงานวิจัยบางชิ้นที่ผสมหลายเทคนิคได้แก่การจับภาพใบหน้า กับการจับภาพการเคลื่อนไหวของศีรษะ และการจับจุดอวัยวะบนใบหน้าร่วมกันเลย ได้แก่ <a href="https://arxiv.org/abs/1603.01249" rel="noreferrer noopener">HyperFace</a>, <a href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html" rel="noreferrer noopener">MTCNN</a> หรืออื่น ๆ</p>
<p>อย่างไรก็ดี ปัญหาของเทคนิครุ่นเก่าคือประมวลผลนานมากกว่าปกติ (ในเอกสารงานวิจัยจะพูดถึง Computational Complexity) ไม่ทันใจวัยรุ่น ความแม่นยำก็ไม่ได้สูงไปกว่าเทคนิคที่กล่าวถึงในหัวข้อก่อนหน้านั้น แถมตอนสอบ อาจารย์ก็พูดถึงเทคนิค <a href="https://arxiv.org/pdf/1703.07332.pdf" rel="noreferrer noopener">FAN (Face Alignment Network)</a> ร่วมด้วยที่มีหัวข้อว่า How far are we from solving the 2D &amp; 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks) เลยนำเทคนิคนี้มาทดสอบก่อน โดยดาวน์โหลดโค้ดจาก <a href="https://github.com/1adrianb/face-alignment" rel="noreferrer noopener">Github</a></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/06/2021-06-25-4.png?w=580&#038;ssl=1" class="kg-image" alt="" loading="lazy" /><figcaption>เทคนิค FAN จากเอกสาร How far are we from solving the 2D &amp; 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)</figcaption></figure>
<p>เทคนิค FAN เป็นเทคนิคการจับจุดอวัยวะบนใบหน้าโดยใช้ Neural Network Architecture แบบ <a href="https://arxiv.org/abs/1603.06937" rel="noreferrer noopener">Hourglass Network</a> ซึ่งทดสอบแล้วแม่นยำกว่าเทคนิคเก่าในอดีต แต่อย่างไรก็ดี เมื่อนำมาทดสอบจริงแล้วยังติดเรื่องความแม่นยำการจับภาพอยู่ดี</p>
<p>ระหว่างนั้นลองเทคนิคการจับภาพใบหน้าเทคนิคอื่นอย่างเช่น <a href="https://xuanyidong.com/publication/cvpr-2018-san/" rel="noreferrer noopener">Style Aggregated Network</a>, <a href="https://xuanyidong.com/publication/cvpr-2018-sbr/" rel="noreferrer noopener">Supervision-by-registraion</a>, <a href="https://openaccess.thecvf.com/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf" rel="noreferrer noopener">dlib</a> หรืออื่น ๆ ซึ่งแม่นยำไหม ก็พอได้ระดับหนึ่ง แต่ยังไม่แม่นยำมากจนพอใจ และยังทำงานช้าไม่ทันใจ</p>
<p>เราค้นหาไปจนเจอเทคนิคหนึ่งที่เรียกว่า 3DDFA_V2 ตามวารสารงานวิจัยที่มีชื่อว่า <a href="https://guojianzhu.com/assets/pdfs/3162.pdf" rel="noreferrer noopener">Towards Fast, Accurate and Stable 3D Dense Face Alignment</a></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/06/3DDFA_V2.png?w=580&#038;ssl=1" class="kg-image" alt="" loading="lazy" /><figcaption>เทคนิค 3DDFA_V2 จากเอกสารงานวิจัย Towards Fast, Accurate and Stable 3D Dense Face Alignment</figcaption></figure>
<p>เทคนิคนี้นำภาพใบหน้าที่จับภาพมาได้ ประมวลผลผ่าน Neural Network Architecture อย่าง MobileNetV2 ที่มีโครงสร้างที่มีขนาดเล็ก ทำงานได้เร็ว ใช้ทรัพยากรต่ำกว่าเทคนิคอื่นอย่าง ResNet, VGG ให้ค่าพารามิเตอร์ที่จำเป็นต่อการประมวลผลผ่าน 3D Morphable Model ให้แปลงจุด 2 มิติ เป็น 3 มิติ แล้วใช้แก้สมการผ่าน Rotation Matrix เพื่อให้ได้องศาการเคลื่อนไหวของศีรษะและลำคอ</p>
<p>เมื่ออ่านเทคนิคนี้แล้ว เราโหลดมาใช้งานผ่าน <a href="https://github.com/cleardusk/3DDFA_V2" rel="noreferrer noopener">Github</a> ทดสอบเทคนิคกับฐานข้อมูลสาธารณะ รวมถึงภาพที่จับภาพมาได้พบว่าได้ความแม่นยำมากกว่าเทคนิคอื่น เลยนำไปใช้งานจริง ก็พบว่าทำงานได้เร็ว ใช้ทรัพยากรที่ต่ำพอที่จะนำ Surface Pro X (ที่อัพเกรตจากวินโดว์ 10 เป็นวินโดว์ 11 ได้สบาย) มาประมวลผลได้โดยไม่มีปัญหาอะไร</p>
<p>สำหรับผู้อ่านที่สนใจ ผู้อ่านสามารถดาวน์โหลดโค้ดจากเว็บ <a href="https://github.com/cleardusk/3DDFA_V2" rel="noreferrer noopener">Github</a> และอ่านเอกสารงานวิจัยได้ใน<a href="https://guojianzhu.com/assets/pdfs/3162.pdf" rel="noreferrer noopener">ลิ้งค์นี้</a>ครับ</p>
<h2 id="-">ข้อมูลเพิ่มเติม</h2>
<p>สำหรับผู้อ่านที่สนใจข้อมูลเพิ่มเติมของเทคนิคการจับภาพการเคลื่อนไหวของศีรษะ รวมถึงเทคนิคการมาร์คจุดบนใบหน้า สามารถอ่านเพิ่มเติมได้ในเอกสารงานวิจัยที่มีชื่อว่า <a href="http://cvrr.ucsd.edu/publications/2009/MurphyChutorian_Trivedi_PAMI09.pdf" rel="noreferrer noopener">Head Pose Estimation in Computer Vision : A Survey</a> กับ <a href="https://arxiv.org/pdf/1805.05563.pdf" rel="noreferrer noopener">Facial Landmark Detection: a Literature Survey</a> ครับ</p>
<p class = 'license'>
    <a href="#top">&uarr; Go to top</a>
</p></article><div class = 'license'>
    <hr />
    <p >
        &copy; 2025. Nick Untitled. / <a href = '/privacy-policy/'>Privacy Policy</a>
    </p>
</div>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RBEMC5RVL9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RBEMC5RVL9');
</script></div>
    </main>
  </body>
</html>