<!DOCTYPE html>
<html lang="en-US" data-theme="light">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0,viewport-fit=cover">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<title>พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้ - Nick Untitled</title>
		<meta name="description" content="เทคนิคการจับภาพการเคลื่อนไหวศีรษะได้รับการพัฒนาตั้งแต่อดีตจนถึงปัจจุบันส่งผลให้ความแม่นยำเพิ่มขึ้นตลอด ในบทความนี้เราจะพูดถึงเทคนิคที่นำใช้อยู่่ในขณะนี้ครับ">
		<meta name="keywords" content="3DDFA,3DDFA_V2,alignment,artificial intelligence,cervical,deep learning,detection,face,FAN,head,Head Pose Estimation,Hopenet,keypoints,landmark,machine learning,measurement,movement,pose,range of motion,">
		<base href="https://nickuntitled.com" />
		
    	<meta content="2021-06-26T00:21:34+07:00" property="article:published_time">
    	<meta content="https://nickuntitled.com/about/" property="article:author">
  		
		<meta property="og:site_name" content="Nick Untitled">
		<meta property="og:type" content="article" />
		<meta property="og:url" content="https://nickuntitled.com/2021/06/26/head-pose-estimation-in-my-thesis-now/"/>
		<meta property="og:title" content="พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้ - Nick Untitled" />
		<meta property="og:description" content="เทคนิคการจับภาพการเคลื่อนไหวศีรษะได้รับการพัฒนาตั้งแต่อดีตจนถึงปัจจุบันส่งผลให้ความแม่นยำเพิ่มขึ้นตลอด ในบทความนี้เราจะพูดถึงเทคนิคที่นำใช้อยู่่ในขณะนี้ครับ " />
		<meta property="og:image" content="https://asset.nickuntitled.com/2021/06/Head-Pose-in-Thesis.jpg"/>
		<meta name="twitter:card" content="summary_large_image"/>
		<meta property="twitter:title" content="พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้ - Nick Untitled" />
		<meta property="twitter:description" content="เทคนิคการจับภาพการเคลื่อนไหวศีรษะได้รับการพัฒนาตั้งแต่อดีตจนถึงปัจจุบันส่งผลให้ความแม่นยำเพิ่มขึ้นตลอด ในบทความนี้เราจะพูดถึงเทคนิคที่นำใช้อยู่่ในขณะนี้ครับ " />
		<meta property="twitter:image" content="https://asset.nickuntitled.com/2021/06/Head-Pose-in-Thesis.jpg" />
		<link rel="stylesheet" href="assets/css/reset.css">
		<link rel="stylesheet" href="assets/css/highlight.css">
		<link rel="stylesheet" href="assets/css/style.css">
		<link rel="shortcut icon" href="assets/images/favicon.png" />
		<link rel="alternate" type="application/atom+xml" title="Nick Untitled" href="https://nickuntitled.com/atom.xml">
		<link rel="alternate" type="application/json" title="Nick Untitled" href="https://nickuntitled.com/feed.json" />
		<link rel="sitemap" type="application/xml" title="sitemap" href="https://nickuntitled.com/sitemap.xml" />
		<meta name="google-site-verification" content="XXX" />
		<meta name="facebook-domain-verification" content="zjykrcwf7cljpxppixh5ior67ehtw2" />
	</head>
<body>

<div class="container">
	<div class="profile">
		<div class="profile-about">
			<div>
				<h2>Nick Untitled</h2>
			</div>
			<div>
				Writing as my personal diary
			</div>
			<div>
				<ul class = 'go_right'>
					<li><a href = '/'><img src="assets/images/icon/home.svg" class="social-icon"></a></li>
					
					
					<li><a href = 'https://twitter.com/nicknznick' target="_blank"><img src="assets/images/icon/twitter.svg" class="social-icon"></a></li>
					
					
					
					<li><a href = 'https://github.com/nickuntitled' target="_blank"><img src="assets/images/icon/github.svg" class="social-icon"></a></li>
					
					
					<li><a href = 'feed.xml'><img src="assets/images/icon/rss.svg" class="social-icon"></a></li>
					<li><a href = 'about'><img src="assets/images/icon/me.svg" class="social-icon"></a></li>
					<li class="mode" id="mode-switcher" onclick="toggleNightMode();">
						<span></span>
					</li>
				</ul>
			</div>
		</div>
	</div>

	
<div class="blog-post-header">
	<h1>พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้</h1>
</div>

<div class="post-header">
	<div class="post-date">26.06.2021</div>
	<div class="post-share">
		Share:&nbsp; 
		<a href="https://www.facebook.com/sharer/sharer.php?u=https://nickuntitled.com/head-pose-estimation-in-my-thesis-now" target="_blank"><img src="assets/images/icon/facebook.svg" class="social-icon"></a>
		<a href="https://twitter.com/intent/tweet?source=tweetbutton&amp;original_referer=https://nickuntitled.com/head-pose-estimation-in-my-thesis-now&amp;text=พูดถึง Head Pose Estimation ที่ใช้ในขณะนี้ - https://nickuntitled.com/head-pose-estimation-in-my-thesis-now" target="_blank"><img src="assets/images/icon/twitter.svg" class="social-icon"></a>
	</div>
</div>

	<figure>
		<img src = 'https://asset.nickuntitled.com/2021/06/Head-Pose-in-Thesis.jpg' />
	</figure>
	
<div class="blog-post-content">
	<!-- wp:paragraph -->
<p><strong>Head Pose Estimation</strong> คือเทคนิคการจับภาพการเคลื่อนไหวของศีรษะเมื่อเทียบกับมุมกล้องที่ถ่ายอยู่ในขณะที่จับภาพ โดยนำภาพใบหน้าของบุคคลที่จับภาพได้จากเทคนิคการจับภาพใบหน้าที่ได้กล่าวถึงในบทความก่อนหน้านี้มาประมวลผลผ่านเทคนิคหนึ่งแล้วระบุเป็นองศาการเคลื่อนไหวของศีรษะใน 3 ทิศทางได้แก่ หันศีรษะซ้าย-ขวา (Yaw), ก้ม-เงยศีรษะ (Pitch) และเอนศีรษะซ้าย-ขวา (Roll)</p>
<!-- /wp:paragraph -->

<!-- wp:more -->
<!--more-->
<!-- /wp:more -->

<!-- wp:image {"align":"center","id":2488,"width":464,"height":302,"sizeSlug":"large","linkDestination":"none"} -->
<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img src="https://asset.nickuntitled.com/2021/06/head-pose-survey.png" alt="" class="wp-image-2488" /><figcaption>ทิคทางการหันศีรษะ Yaw, Pitch และ Roll จากเอกสาร Head Pose Estimation in Computer Vision : A Survey</figcaption></figure></div>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>ซึ่งในอดีตจนมาถึงปัจจุบันมีการพัฒนาเทคนิคมาเรื่อย ๆ จนกระทั่งมาถึงปัจจุบันที่นำเทคนิคการเรียนรู้เชิงลึก (Deep Learning) มาใช้งานร่วมด้วย หลังจากการพัฒนาเทคนิค <a href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" target="_blank" rel="noreferrer noopener" title="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">AlexNet ที่ได้ความแม่นยำจากการทดสอบกับฐานข้อมูล ImageNet</a> เนื่องมาจากได้ความแม่นยำ (Accuracy) ที่มากกว่าเทคนิคอื่น กับสามารถจับลักษณะภาพได้โดยอัตโนมัติ (Automatic Feature Extraction) โดยในงานวิจัยที่ทำอยู่นำเทคนิคเหล่านี้มาใช้งาน</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>เทคนิคหนึ่งที่เรานำมาใช้คือ Hopenet </p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2>Hopenet</h2>
<!-- /wp:heading -->

<!-- wp:image {"align":"center","id":2475,"width":1027,"height":418,"sizeSlug":"large","linkDestination":"none"} -->
<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img src="https://asset.nickuntitled.com/2021/06/hopenet-architecture.png" alt="" class="wp-image-2475" /><figcaption>เทคนิค Hopenet จากเอกสาร Fine-Grained Head Pose Estimation Without Keypoints</figcaption></figure></div>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>เทคนิค Hopenet (เผยแพร่ในเอกสารงานวิจัยที่มีหัวข้อว่า <a href="https://arxiv.org/abs/1710.00925" target="_blank" rel="noreferrer noopener">Fine-Grained Head Pose Estimation Without Keypoints</a>) นี้ที่นำภาพใบหน้าผ่านกระบวนการการเรียนรู้เชิงลึก (Deep Learning) ที่ใช้โครงการเครือข่ายประสาท (Neural Network Architecture) แบบ <a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noreferrer noopener" title="https://arxiv.org/abs/1512.03385">ResNet-50</a> แล้วให้ประเมินออกมาเป็นการเคลื่อนไหวของศีรษะและลำคอ 3 ทิศทาง </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>เราเลยนำเทคนิคนี้จากเว็บ <a href="https://github.com/natanielruiz/deep-head-pose" target="_blank" rel="noreferrer noopener">Github</a> มาทดสอบในเบื้องต้น (Preliminary Study) แล้วได้ความแม่นยำจากการทดสอบฐานข้อมูลสาธารณะอย่าง <a href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm" target="_blank" rel="noreferrer noopener" title="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm">AFLW2000</a> และ <a href="https://www.kaggle.com/kmader/biwi-kinect-head-pose-database" target="_blank" rel="noreferrer noopener" title="https://www.kaggle.com/kmader/biwi-kinect-head-pose-database">BIWI</a> มากกว่าเทคนิคอื่นในขณะนั้น </p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>อย่างไรก็ดีงานวิจัยที่ทำอยู่นี้เราต้องจับภาพบริเวณริมฝีปากร่วมด้วย ดังนั้นแล้วเทคนิคนี้เลยไม่ได้ใช้ แล้วจะต้องทำอย่างไรดีล่ะ? เรามาพูดถึงหัวข้อถัดไปดีกว่า ที่เรียกว่า Facial Landmark Detection</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2>Facial Landmark Detection</h2>
<!-- /wp:heading -->

<!-- wp:image {"align":"center","id":2499,"sizeSlug":"large","linkDestination":"none"} -->
<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://asset.nickuntitled.com/2021/06/landmark-result.jpg" alt="" class="wp-image-2499" /><figcaption>Facial Landmark Detection</figcaption></figure></div>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p><strong>Facial Landmark Detection</strong> คือกระบวนการจับจุดแลนมาร์คตำแหน่งอวัยวะบนใบหน้าซึ่งเป็นกระบวนการที่สำคัญต่อการนำไปใช้ประมวลผลต่อในงานด้าน Computer Vision งานอื่นต่อไป ได้แก่ กระบวนการการจับภาพการเคลื่อนไหวศีรษะ (Head Pose Estimation) กับกระบวนการจับภาพอารมณ์บนใบหน้า (Facial Emotion Recognition) เป็นต้น</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>เทคนิคนี้ได้รับการพัฒนามานานเกิน 20 ปีได้แล้ว โดยเทคนิคช่วงแรก ๆ จะเป็นการจับภาพทั้งภาพใบหน้า แล้วแกะลักษณะภาพบนใบหน้า (Feature) เพื่อนำไปประมวลผลผ่านเทคนิคการเรียนรู้ (Machine Learning) ได้แก่ </p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><li>Active Shape Model, Active Appearance Model ที่แปลงภาพผ่าน PCA (Principal Component Analysis)</li><li>Constrained Local Model ที่ใช้ Point Distribution Model ร่วมกันกับใช้ตำแหน่งภาพตามอวัยวะต่าง ๆ เพื่อปรับจุดบนใบหน้าให้แม่นยำขึ้น </li><li>เป็นต้น</li></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>จนกระทั่ง AlexNet ได้รับการพัฒนาขึ้น มีเทคนิคที่พัฒนาขึ้นจากการเรียนรู้เชิงลึก (Deep Learning) แล้วได้ความแม่นยำมากกว่าเทคนิคอื่น นอกเหนือจากนี้มีงานวิจัยบางชิ้นที่ผสมหลายเทคนิคได้แก่การจับภาพใบหน้า กับการจับภาพการเคลื่อนไหวของศีรษะ และการจับจุดอวัยวะบนใบหน้าร่วมกันเลย ได้แก่ <a href="https://arxiv.org/abs/1603.01249" target="_blank" rel="noreferrer noopener" title="https://arxiv.org/abs/1603.01249">HyperFace</a>, <a href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html" target="_blank" rel="noreferrer noopener" title="https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html">MTCNN</a> หรืออื่น ๆ</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>อย่างไรก็ดี ปัญหาของเทคนิครุ่นเก่าคือประมวลผลนานมากกว่าปกติ (ในเอกสารงานวิจัยจะพูดถึง Computational Complexity) ไม่ทันใจวัยรุ่น ความแม่นยำก็ไม่ได้สูงไปกว่าเทคนิคที่กล่าวถึงในหัวข้อก่อนหน้านั้น แถมตอนสอบ อาจารย์ก็พูดถึงเทคนิค <a href="https://arxiv.org/pdf/1703.07332.pdf" target="_blank" rel="noreferrer noopener" title="https://arxiv.org/pdf/1703.07332.pdf">FAN (Face Alignment Network)</a> ร่วมด้วยที่มีหัวข้อว่า How far are we from solving the 2D &amp; 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks) เลยนำเทคนิคนี้มาทดสอบก่อน โดยดาวน์โหลดโค้ดจาก <a href="https://github.com/1adrianb/face-alignment" target="_blank" rel="noreferrer noopener">Github</a></p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":2486,"width":687,"height":203,"sizeSlug":"large","linkDestination":"none"} -->
<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img src="https://asset.nickuntitled.com/2021/06/2021-06-25-4.png" alt="" class="wp-image-2486" /><figcaption>เทคนิค FAN จากเอกสาร How far are we from solving the 2D &amp; 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)</figcaption></figure></div>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>เทคนิค FAN เป็นเทคนิคการจับจุดอวัยวะบนใบหน้าโดยใช้ Neural Network Architecture แบบ <a href="https://arxiv.org/abs/1603.06937" target="_blank" rel="noreferrer noopener" title="https://arxiv.org/abs/1603.06937">Hourglass Network</a> ซึ่งทดสอบแล้วแม่นยำกว่าเทคนิคเก่าในอดีต แต่อย่างไรก็ดี เมื่อนำมาทดสอบจริงแล้วยังติดเรื่องความแม่นยำการจับภาพอยู่ดี</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>ระหว่างนั้นลองเทคนิคการจับภาพใบหน้าเทคนิคอื่นอย่างเช่น <a href="https://xuanyidong.com/publication/cvpr-2018-san/" target="_blank" rel="noreferrer noopener" title="https://xuanyidong.com/publication/cvpr-2018-san/">Style Aggregated Network</a>, <a href="https://xuanyidong.com/publication/cvpr-2018-sbr/" target="_blank" rel="noreferrer noopener" title="https://xuanyidong.com/publication/cvpr-2018-sbr/">Supervision-by-registraion</a>, <a href="https://openaccess.thecvf.com/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf" target="_blank" rel="noreferrer noopener" title="https://openaccess.thecvf.com/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf">dlib</a> หรืออื่น ๆ ซึ่งแม่นยำไหม ก็พอได้ระดับหนึ่ง แต่ยังไม่แม่นยำมากจนพอใจ และยังทำงานช้าไม่ทันใจ</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>เราค้นหาไปจนเจอเทคนิคหนึ่งที่เรียกว่า 3DDFA_V2 ตามวารสารงานวิจัยที่มีชื่อว่า <a href="https://guojianzhu.com/assets/pdfs/3162.pdf" title="https://guojianzhu.com/assets/pdfs/3162.pdf" target="_blank" rel="noreferrer noopener">Towards Fast, Accurate and Stable 3D Dense Face Alignment</a></p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":2485,"width":488,"height":298,"sizeSlug":"large","linkDestination":"none"} -->
<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img src="https://asset.nickuntitled.com/2021/06/3DDFA_V2.png" alt="" class="wp-image-2485" /><figcaption>เทคนิค 3DDFA_V2 จากเอกสารงานวิจัย Towards Fast, Accurate and Stable 3D Dense Face Alignment</figcaption></figure></div>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>เทคนิคนี้นำภาพใบหน้าที่จับภาพมาได้ ประมวลผลผ่าน Neural Network Architecture อย่าง MobileNetV2 ที่มีโครงสร้างที่มีขนาดเล็ก ทำงานได้เร็ว ใช้ทรัพยากรต่ำกว่าเทคนิคอื่นอย่าง ResNet, VGG ให้ค่าพารามิเตอร์ที่จำเป็นต่อการประมวลผลผ่าน 3D Morphable Model ให้แปลงจุด 2 มิติ เป็น 3 มิติ แล้วใช้แก้สมการผ่าน Rotation Matrix เพื่อให้ได้องศาการเคลื่อนไหวของศีรษะและลำคอ</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>เมื่ออ่านเทคนิคนี้แล้ว เราโหลดมาใช้งานผ่าน <a href="https://github.com/cleardusk/3DDFA_V2" target="_blank" rel="noreferrer noopener" title="https://github.com/cleardusk/3DDFA_V2">Github</a> ทดสอบเทคนิคกับฐานข้อมูลสาธารณะ รวมถึงภาพที่จับภาพมาได้พบว่าได้ความแม่นยำมากกว่าเทคนิคอื่น เลยนำไปใช้งานจริง ก็พบว่าทำงานได้เร็ว ใช้ทรัพยากรที่ต่ำพอที่จะนำ Surface Pro X (ที่อัพเกรตจากวินโดว์ 10 เป็นวินโดว์ 11 ได้สบาย) มาประมวลผลได้โดยไม่มีปัญหาอะไร</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>สำหรับผู้อ่านที่สนใจ ผู้อ่านสามารถดาวน์โหลดโค้ดจากเว็บ <a href="https://github.com/cleardusk/3DDFA_V2" target="_blank" rel="noreferrer noopener" title="https://github.com/cleardusk/3DDFA_V2">Github</a> และอ่านเอกสารงานวิจัยได้ใน<a href="https://guojianzhu.com/assets/pdfs/3162.pdf" target="_blank" rel="noreferrer noopener" title="https://guojianzhu.com/assets/pdfs/3162.pdf">ลิ้งค์นี้</a>ครับ</p>
<!-- /wp:paragraph -->

<!-- wp:heading -->
<h2>ข้อมูลเพิ่มเติม</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>สำหรับผู้อ่านที่สนใจข้อมูลเพิ่มเติมของเทคนิคการจับภาพการเคลื่อนไหวของศีรษะ รวมถึงเทคนิคการมาร์คจุดบนใบหน้า สามารถอ่านเพิ่มเติมได้ในเอกสารงานวิจัยที่มีชื่อว่า <a href="http://cvrr.ucsd.edu/publications/2009/MurphyChutorian_Trivedi_PAMI09.pdf" target="_blank" rel="noreferrer noopener">Head Pose Estimation in Computer Vision : A Survey</a> กับ <a href="https://arxiv.org/pdf/1805.05563.pdf" target="_blank" rel="noreferrer noopener">Facial Landmark Detection: a Literature Survey</a> ครับ</p>
<!-- /wp:paragraph -->

</div>
<div class="tags-container">
	
		<span class="post-tag">3DDFA</span>, 
	
		<span class="post-tag">3DDFA_V2</span>, 
	
		<span class="post-tag">alignment</span>, 
	
		<span class="post-tag">artificial intelligence</span>, 
	
		<span class="post-tag">cervical</span>, 
	
		<span class="post-tag">deep learning</span>, 
	
		<span class="post-tag">detection</span>, 
	
		<span class="post-tag">face</span>, 
	
		<span class="post-tag">FAN</span>, 
	
		<span class="post-tag">head</span>, 
	
		<span class="post-tag">Head Pose Estimation</span>, 
	
		<span class="post-tag">Hopenet</span>, 
	
		<span class="post-tag">keypoints</span>, 
	
		<span class="post-tag">landmark</span>, 
	
		<span class="post-tag">machine learning</span>, 
	
		<span class="post-tag">measurement</span>, 
	
		<span class="post-tag">movement</span>, 
	
		<span class="post-tag">pose</span>, 
	
		<span class="post-tag">range of motion</span>
	
</div>
<div class="navigation">
	
		<a class="prev" href="/2021/06/17/remove-social-news-feed-by-eradicator/">< ซ่อนฟีตบน Social โดย News Feed Eradicator</a>
	 
	<a class="next" href="/2021/06/26/bring-social-post-read-rss-reader-by-rss-dot-app/">นำโพสโซเชียลมาอ่านบน RSS Reader โดย rss.app ></a>

</div>
	
</div>

<div class="footer">
	<span>
		<div class = 'go_left'>
			<p>
				<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
			</p>
			<p>
				Made with <font color="red">♥</font> on Earth, a minimalist Jekyll Theme by <a href="https://hakan.io"><b>Hakan</b></a> modified a little bit by <a href = 'https://nickuntitled.com'><b>Nick Untitled</b></a>
			</p>
		</div>	

		<div class = 'go_right'>
			<p>
				<strong class = 'top_footer_link'>Links</strong>
			</p>
			<p>
				<ul>
					
					
					<li><a href = 'https://twitter.com/nicknznick' target="_blank">Twitter</a></li>
					
					
					
					<li><a href = 'https://github.com/nickuntitled' target="_blank">Github</a></li>
					
					<li><a href = 'about'>About Me</a></li>
					<li><a href = 'privacy-policy'>Privacy Policy</a></li>
				</ul>
			</p>
		</div>
	</span>
</div>

	<script src="assets/js/ephesus.js"></script>
	<script type="text/javascript">
		if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
			document.documentElement.setAttribute('data-theme', 'dark');
			document.getElementById('mode-switcher').classList.add('active');
		}
	</script>

	
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-46662350-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-46662350-1');
    </script>
	
</body>
</html>