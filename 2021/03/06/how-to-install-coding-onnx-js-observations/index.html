<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>การติดตั้ง เขียนโค้ดเพื่อใช้งาน ONNX.js และข้อสังเกต</title><!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="การติดตั้ง เขียนโค้ดเพื่อใช้งาน ONNX.js และข้อสังเกต" />
<meta name="author" content="Kittisak Chotikkakamthorn" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="None" />
<meta property="og:description" content="None" />
<link rel="canonical" href="http://localhost:4000/2021/03/06/how-to-install-coding-onnx-js-observations/" />
<meta property="og:url" content="http://localhost:4000/2021/03/06/how-to-install-coding-onnx-js-observations/" />
<meta property="og:site_name" content="Nick Untitled" />
<meta property="og:image" content="https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/03/1564d343-1f0d-4c31-b7bb-6383071b3eec-1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-06T23:18:12+07:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/03/1564d343-1f0d-4c31-b7bb-6383071b3eec-1.png" />
<meta property="twitter:title" content="การติดตั้ง เขียนโค้ดเพื่อใช้งาน ONNX.js และข้อสังเกต" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Kittisak Chotikkakamthorn"},"dateModified":"2024-03-16T09:47:51+07:00","datePublished":"2021-03-06T23:18:12+07:00","description":"None","headline":"การติดตั้ง เขียนโค้ดเพื่อใช้งาน ONNX.js และข้อสังเกต","image":"https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/03/1564d343-1f0d-4c31-b7bb-6383071b3eec-1.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2021/03/06/how-to-install-coding-onnx-js-observations/"},"url":"http://localhost:4000/2021/03/06/how-to-install-coding-onnx-js-observations/"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Nick Untitled" /><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
  <link rel="stylesheet" href="/assets/css/reset.css" />
  <link rel="stylesheet" href="/assets/css/normalize.css" />
  <link rel="stylesheet" href="/assets/css/main.css" />
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.css" integrity="sha384-OH8qNTHoMMVNVcKdKewlipV4SErXqccxxlg6HC9Cwjr5oZu2AdBej1TndeCirael" crossorigin="anonymous">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Thai:wght@700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Chakra+Petch:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
</head>
<body a="auto">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <p class = 'back-meta'>
    <a href="/">&lt; Nick Untitled</a>
</p><article>
  <h1 class = 'post-title'>การติดตั้ง เขียนโค้ดเพื่อใช้งาน ONNX.js และข้อสังเกต</h1>

  <p class="post-meta">
    <time datetime="2021-03-06 23:18:12 +0700">2021-03-06</time>
  </p>

  
  <figure class = 'featured-image'>
      <img src = 'https://sgp1.digitaloceanspaces.com/nickuntitledasset/2021/03/1564d343-1f0d-4c31-b7bb-6383071b3eec-1.png' />
  </figure>
  

  <p><strong>อัพเดท: </strong>ตัวไลบรารีได้รับการพัฒนาต่อแล้วครับ อ่านได้ในรายละเอียดหัวข้ออัพเดทด้านล่างของบทความครับ</p>

<p>การนำโมเดลที่ได้รับการเรียนรู้แล้วมาทำงานบนเว็บเบราว์เซอร์ไม่ได้เป็นเรื่องใหม่นัก เพราะบริษัทกูเกิ้ลพัฒนาไลบรารีชื่อ Tensorflow.js โดยเรานำโมเดลที่ได้รับการเรียนรู้แล้วมาทำนาย หรือเรียนรู้ข้อมูลใหม่บนเว็บไซต์ได้เลยโดยไม่จำเป็นต้องส่งข้อมูลไปทำนายบนเซิร์ฟเวอร์</p>

<!--more-->

<p>ส่วนไลบรารี <a href="https://github.com/microsoft/onnxjs" rel="noreferrer noopener">ONNX.js</a> เป็นส่วนหนึ่งของไลบรารี <a href="https://onnx.ai/" rel="noreferrer noopener">ONNX (Open Neural Network Exchange)</a> ที่ได้รับการพัฒนาโดยบริษัทไมโครซอฟท์ เพื่อให้นำโมเดลที่ได้รับการเรียนรู้จากไลบรารี Deep learning ต่าง ๆ ได้แก่ PyTorch, Mxnet, Scikit learn เป็นต้น มาแปลงเพื่อนำไปใช้กันกับไลบรารีอื่นได้เลย หรือนำโมเดลที่เรียนรู้มาทำนายข้อมูล (Inference) ได้ โดยไลบรารี ONNX.js นี้ เปิดให้นักพัฒนาที่เทรนข้อมูลมาแล้ว เอามาทำนายข้อมูลที่มีอยู่บนเว็บเบราวเซอร์ (หรือบนคอมพิวเตอร์ผ่าน Node.js) ได้โดยไม่จำเป็นต้องมาเรียนรู้ใหม่อีก</p>

<figure class="wp-block-image"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/03/screen-shot-2564-03-06-at-22.52.39.png?w=580&#038;ssl=1" alt="" /><figcaption>ไลบรารี ONNX</figcaption></figure>

<p>ข้อดีของการนำโมเดลที่ได้รับการเรียนรู้มาทำงานบนเว็บเบราวเซอร์โดยการใช้ไลบรารี ONNX.js หรือ Tensorflow.js เมื่อเปรียบเทียบกับการส่งข้อมูลไปทำงานบนเซิร์ฟเวอร์ มี 3 ข้อ ได้แก่</p>

<ol class="wp-block-list"><li>ความเป็นส่วนตัว (Privacy) ที่เหนือกว่าการส่งข้อมูลไปยังเซิร์ฟเวอร์ เพราะเราไม่ต้องส่งข้อมูลส่วนตัว ข้อมูลที่ sensitive ไปให้เซิร์ฟเวอร์อ่าน</li><li>ระยะเวลาที่ทำงานโมเดลน้อยกว่าเนื่องจากมีค่า Latency ที่ต่ำกว่า เพราะเราไม่ต้องส่งข้อมูลไป และนำข้อมูลที่มีอยู่ในคอมของลูกค้ามาทำนายในเว็บเบราวเซอร์ได้เลย</li><li>สามารทำงานข้ามแพลตฟอร์ม (Cross-platform) ได้เลยโดยไม่ต้องคอมไพล์ใหม่ หรือไม่ต้องมาลงไลบรารีใหม่แบบที่เคยพัฒนา และทำนายโดยใช้ภาษาไพทอน</li></ol>

<p>เมื่อเห็นข้อดีการใช้ไลบรารีขนาดนี้แล้ว จะรอช้าอยู่ไรล่ะ เรามาติดตั้ง พร้อมกับเขียนโปรแกรมเพื่อใช้งาน ONNX.js กันดีกว่า</p>

<h2 class="wp-block-heading" id="-onnx-js">การติดตั้งและใช้ไลบรารี ONNX.js</h2>

<p><strong>การติดตั้งไลบรารี ONNX.js</strong></p>

<p>ของเราเดิมทีมีตัวจับภาพใบหน้า (Face detection) ที่นำอัลกอริทีม RetinaFace ที่ผ่านการเรียนรู้โดย PyTorch มาแปลงเก็บไว้ในรูปแบบไฟล์ที่ ONNX อ่านได้เพื่อนำมาใช้งานกับธีสิสที่ต้องการทำนายบนเว็บแทน เนื่องจากโค้ดได้รับการพัฒนาโดย JavaScript วิธีการทำนายข้อมูลนี้ทำได้โดย</p>

<p>การติดตั้งไลบรารี ONNX.js ทำได้โดยกรณีที่ต้องการทำงานบนเบราวเซอร์แบบที่ไม่ได้ใช้ไลบรารีอื่นอย่าง React, Angular, Vue.js ทำได้โดยดาวน์โหลดจาก<a href="https://cdn.jsdelivr.net/npm/onnxjs/dist/" rel="noreferrer noopener">ลิ้งค์นี้</a>ได้เลยครับ เมื่อดาวน์โหลดมาแล้ว นำไฟล์ของไลบรารีเข้าไปในตัวเว็บไซต์โดยผ่านการใช้ &lt;script&gt; ตามด้านล่างนี้</p>

<p><code>&lt;script src="<a href="https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js&quot;&gt;&lt;/script&amp;gt">https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js"&gt;&lt;/script&gt;</a>;</code></p>

<p>ส่วนคนที่ใช้ไลบรารีตามที่กล่าวไว้ข้างต้น หรือไลบรารีอื่นใด เราสามารถนำเข้า ONNX.js ผ่านการติดตั้งจาก NPM โดยใช้คำสั่ง npm install หรือ yarn add ได้ตามสะดวก จากนั้นใช้คำสั่ง import เข้ามาครับตามด้านล่างนี้</p>

<p><code>import { Tensor, InferenceSession } from "onnxjs";</code></p>

<p><strong>การเขียนโค้ดเพื่ออินพอร์ทโมเดล</strong></p>

<p>เมื่อเรานำเข้าไลบรารีมาแล้ว ขั้นตอนต่อไปคือเขียนโค้ดด้วยภาษา JavaScript เพื่ออิมพอร์ทตัวโมเดลเพื่อที่จะทำนายข้อมูลที่เรามีอยู่ ทำได้โดย</p>

<p><code>const onnxsession = new onnx.InferenceSession({ backendHint: 'webgl' }); </code></p>

<p><code>await onnxsession.loadModel("model path in http:// form");</code></p>

<p>โดยในตัวโค้ดจะใช้คำสั่ง await (เรียกการใช้งานแบบนี้ว่า <a href="https://www.borntodev.com/2020/03/06/เข้าใจ-await-async-ใน-5-นาที/" rel="noreferrer noopener">async await</a>) แต่ถ้าจะใช้ <a href="https://www.borntodev.com/2020/03/06/เข้าใจ-promise-ใน-5-นาที/" rel="noreferrer noopener">Promise</a> ก็ใช้ได้เช่นกัน ส่วนสำหรับคนที่ไม่ทราบเรื่อง async await กับ Promise ผู้อ่านสามารถตามได้ที่ลิ้งค์ข้างบน</p>

<p><strong>ทำข้อมูลมาทำนาย (Inference)</strong></p>

<p>อินพอร์ทตัวโมเดลแล้วก็ต้องนำข้อมูลที่มีอยู่มาทำนายใช่ไหมครับ ก่อนอื่นเราต้องนำข้อมูลที่มีอยู่แล้วมาแปลงในรูปแบบที่ตัวไลบรารีเข้าใจด้วยการแปลงเป็น Tensor ในตัวยอย่างจะเป็นการนำข้อมูลที่เป็นรูปภาพมาแปลงได้โดย</p>

<p><code>var inputTensor = new onnx.Tensor(preprocessedimg, 'float32', [batch_size, channels, imgwidth, imgheight]);</code></p>

<p>ข้อมูลที่ได้จะอยู่ในรูป Tensor จากนั้นนำมาทำนายโดยพิมพ์ว่า</p>

<p><code>var output = await onnx_session.run([inputTensor]);</code></p>

<p>ข้อมูลนั้นจะถูกทำนายโดยโมเดลที่เราเรียนรู้ไว้</p>

<p><strong>ผลลัพธ์</strong></p>

<figure class="wp-block-image"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/02/2021-02-06.png?w=580&#038;ssl=1" alt="" /></figure>

<p>ผลการนำข้อมูลมาทำนาย</p>

<h2 class="wp-block-heading" id="-"><strong>ประสิทธิภาพในการทำงาน</strong></h2>

<p>ความเร็วในการทำงานขึ้นกับว่าเราใช้ Backend ของอะไรตั้งแต่การเขียนโค้ดเพื่ออินพอร์ทโมเดลในหัวข้อก่อนหน้า โดย Backend เราเลือกได้ 3 รูปแบบได้แก่ cpu ซึ่งทำงานได้ช้าที่สุด, wasm ทำงานโดยใช้ Webassembly ซึ่งตัวโค้ดผ่านการคอมไพล์จะทำงานได้เร็วกว่าตัวเลือก cpu ส่วน webgl ทำงานโดยใช้การ์ดจอซึ่งโดยปกติจะทำงานได้เร็วที่สุด ตามที่ไมโครซอฟท์ได้ทดสอบจะแสดงผลตามกราฟด้านล่างนี้ (เอามาจากในเว็บ GitHub ครับ)</p>

<figure class="wp-block-image"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/github.com/microsoft/onnxjs/raw/master/docs/perf-resnet50.png?w=580&#038;ssl=1" alt="alt text" /><figcaption>กราฟแสดงผลการทดสอบของ ONNX.js (เอามาจาก Github นะ)</figcaption></figure>

<h2 class="wp-block-heading" id="--1"><strong>ข้อสังเกต</strong></h2>

<p>หลังจากที่นำไลบรารีตัวนี้มาใช้งานแล้ว เราสังเกตได้ว่า</p>

<p><strong>ตัวโค้ดมีบัคจากการรันโมเดล</strong></p>

<p>จากการนำตัวโมเดลเพื่อนำไปทดสอบบนเว็บเบราวเซอร์จะขึ้น error ประมาณว่าไม่รองรับ operation บางอย่างในโมเดล deep learning ที่เรานำเข้ามา ซึ่งของเราเป็นโมเดล RetinaFace ที่มี backbone ResNet-50 กับ MobileNetV2 ครับ เท่าที่อ่านใน Issue ของ Github ไลบรารีนี้จะพบว่ามีคนรายงานตัวไลบรารีไม่รองรับ operation Shape แล้วไม่มีทีมงานตอบกลับ แต่ของคนอื่นถ้านำโมเดลมาทดสอบอาจจะไม่พบข้อผิดพลาดข้อนี้ได้ครับ</p>

<figure class="wp-block-image"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/03/screen-shot-2564-03-06-at-22.46.04-edited.png?w=580&#038;ssl=1" alt="" /><figcaption>ข้อผิดพลาดระหว่างการอิมพอร์ตโมเดลครับ</figcaption></figure>

<p>เราเลยแก้ปัญหาเปลี่ยนไฟล์ JavaScript จากที่โหลดผ่าน CDN เป็นไฟล์ที่ผ่านการคอมไพล์ร่วมกันกับแก้ไข backend ให้รันบน Webasm (Webassembly) แทน ซึ่งก็ทำงานได้ แต่ทำงานช้ามาก (ก หลายตัว) กว่าจะเสร็จก็ไปเติมน้ำรอบนึงงานก็ยังไม่เสร็จอยู่ดี ส่วน WebGL ก็ยังเจอปัญหาเดิมอยู่ดี</p>

<p><strong>ไลบรารีนี้มีแนวโน้มไม่ได้รับการพัฒนาต่อ</strong></p>

<p>ถ้าไปดูในตัวไลบรารีใน Github เราจะพบว่าตัวไลบรารีนี้ไม่ได้มีการพัฒนา แก้ไข ดีบัคอย่างต่อเนื่องเลย ไลบรารีนี้ปล่อยออกมาในเวอร์ชันล่าสุด (เวอร์ชัน 0.18) เมื่อเดือนสิงหาคมปีที่แล้ว ซึ่งคิดว่าทีมงานคงไม่ได้พัฒนาต่อ แต่ถ้าเปลี่ยนไปใช้ Tensorflow.js จะดีกว่า เพราะกูเกิ้ลพัฒนาอยู่ตลอด จนตอนนี้อยู่ที่เวอร์ชัน 3 ไปแล้ว และซัพพอร์ตการทำงาน WebGL ได้ดี เพียงแต่ฟังก์ชันอาจจะไม่ครบครันเท่ากับ Tensorflow ที่ทำงานบนไพทอน</p>

<figure class="wp-block-image"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/03/screen-shot-2564-03-06-at-22.49.12-2-edited.png?w=580&#038;ssl=1" alt="" /><figcaption>ไลบรารีนี้ Commit ล่าสุดก็ 2 ปีไปแล้ว ดูแนวโน้มน่าจะไม่ได้พัฒนาต่อ</figcaption></figure>

<p><strong>ทีมงานที่ดูแลไม่ได้ซัพพอร์ต</strong></p>

<p>จากที่สังเกตในเว็บ Github ของไลบรารีจะพบคนรายงานใน Issue เยอะ แต่ไม่มีทีมงาน และไม่มีคนอื่นมาตอบเลย เลยคิดว่าไลบรารีนี้ไม่น่าจะได้รับการซัพพอร์ตแล้ว ผิดกับ Tensorflow.js ครับ</p>

<figure class="wp-block-image"><img data-recalc-dims="1" decoding="async" src="https://nickuntitledasset.sgp1.cdn.digitaloceanspaces.com/2021/03/screen-shot-2564-03-06-at-22.50.37.png?w=580&#038;ssl=1" alt="" /><figcaption>ใน Issue เจอปัญหาแบบที่เราเจอเลยหลายคน แต่ไม่มีคนมาตอบ</figcaption></figure>

<h2 class="wp-block-heading" id="--2">อัพเดท</h2>

<p>ตัวไลบรารี ONNX.js ได้รับการพัฒนาแล้ว ตามที่มีคนตอบไว้ใน<a href="https://github.com/microsoft/onnxruntime/issues/3290" rel="noreferrer noopener">หน้า Github Issue</a> โดยเปลี่ยนชื่อเป็น onnxruntime ที่ใช้ชื่อแบบเดียวกันกับที่ใช้ในรูปแบบภาษาไพทอน อย่างไรก็ดี ยังมีปัญหาตอนรันโมเดลที่ไลบรารีแจ้งว่า ไม่รองรับ Operation บางอย่างในโมเดลที่เรานำเข้ามาใช้</p>

<p>ส่วนรายละเอียดเพิ่มเติม สามารถ<a href="https://onnxruntime.ai/docs/reference/api/js-api.html" rel="noreferrer noopener">อ่านได้ในหน้าเว็บนี้</a></p>

<h2 class="wp-block-heading" id="--3">โดยสรุป</h2>

<p>ไลบรารี ONNX.js เป็นไลบรารีที่ได้รับการพัฒนาขึ้นจากไมโครซอฟท์ที่ต้องการให้นำโมเดลที่ผ่านการเรียนรู้มาทำงานบนเว็บบราวเซอร์ เรียกใช้งานได้ง่าย แต่ติดปัญหาที่สำคัญ ได้แก่ ไลบรารีไม่ซัพพอร์ตบาง operation โครงการดูไม่ได้รับการพัฒนาต่อ และทีมงานไม่ได้ซัพพอร์ต</p>

<p>เลยมีความเห็นกับไลบรารีตัวนี้ว่าไม่ควรใช้ฮะ แนะนำให้ไปใช้งาน Tensorflow.js ไปใช้งานจะทำให้ชีวิตผู้อ่านดีกว่ามาก เพราะเป็นไลบรารีที่พัฒนาโดยกูเกิ้ล ที่ได้รับการซัพพอร์ตอย่างต่อเนื่อง และมีการพัฒนาอยู่ตลอด นอกเหนือจากนี้ไลบรารีเป็นไลบรารีที่ได้รับการแนะนำให้ใช้งานในงาน Production ได้เลย</p>

<p><strong>สรุปคือ</strong> ไปใช้งาน Tensorflow.js ดีกว่า</p>
<p class = 'license'>
    <a href="#top">&uarr; Go to top</a>
</p></article><div class = 'license'>
    <hr />
    <p >
        &copy; 2025. Nick Untitled. / <a href = '/privacy-policy/'>Privacy Policy</a>
    </p>
</div>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RBEMC5RVL9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RBEMC5RVL9');
</script></div>
    </main>
  </body>
</html>